# Agentic RAG chatbot(Client)

- [Agentic RAG chatbot(Client)](#agentic-rag-chatbotclient)
  - [概要](#概要)
  - [画面イメージ](#画面イメージ)
  - [特徴](#特徴)
  - [ソースコードについて](#ソースコードについて)
  - [概要・画面イメージ・特徴](#概要画面イメージ特徴)
  - [環境セットアップ](#環境セットアップ)
    - [Node.jsバージョンの確認](#nodejsバージョンの確認)
    - [必要なOSSのインストール](#必要なossのインストール)
  - [アプリケーションの起動](#アプリケーションの起動)
    - [バックエンドの起動](#バックエンドの起動)
    - [フロントエンドの起動](#フロントエンドの起動)
    - [動作確認](#動作確認)

## 概要

※ English guide: [README.md](/README.md)

- 社内情報を効果的に活用し、柔軟な思考が可能な Agentic RAG チャットボットです。LangGraph を基盤とした AI Agent が自律的に作業計画やタスクを立案し、Web 検索や Vector DB を用いた RAG により最適な回答を提供します。従来の一問一答にとどまらず、回答後も会話や追加分析が継続できる点が特徴です。RAG は Web 検索のように、Agent が呼び出すツールのひとつとして位置付けられます。
- Plan & Execution の Agent パターンも導入しており、Agent が自ら検索計画を作成して適切な検索ツールを実行します。それにより、多角的かつ体系的に情報を収集して回答することができます。

## 画面イメージ

左側がチャットボットです。右側には AI Agent の思考プロセスがリアルタイムに表示されます。

![Screen image](/readme_images/screen_image.png)

※ 日本語モードに切り替えると日本語で使用できます。

## 特徴

- 動作を LLM 任せにすると収束しないことがあるため、計画のステータスを厳格に管理します。確実に収束するよう、計画数の最大値も設定します。
- AI Message や Tool Message の中から必要なメッセージだけを抽出して利用します。Agent が参照するメッセージを最小限に抑えることで、コストを削減できます。
- Plan & Execute パターンを導入して計画を作成することで、多面的かつ体系的に情報を収集できます。
- 複数の内容を含む複雑な依頼にも対応可能で、回答が構造的になります。
  例：A 社の技術情報収集 → B 社の技術情報収集 → A・B 社の技術情報の比較
- LangGraph を使用しています。複雑なフローを構築できるため、細かい要件に合わせたカスタマイズが可能です。
- arxiv にある論文を検索するツールをTool calling functionの一つとして登録しています。ユーザーの依頼を基に Agent が arxiv 用の検索クエリーを作成して検索を行います。

## ソースコードについて

コードがフロントエンド：[agentic_rag_client](https://github.com/DXC-Lab-Linkage/agentic_rag_dxclab_client) とバックエンド：[agentic_rag_server](https://github.com/DXC-Lab-Linkage/agentic_rag_dxclab_server) の 2 つに分かれています。当リポジトリーのコードはフロントエンドのコードです。

## 概要・画面イメージ・特徴

概要・画面イメージ・特徴はサーバー側コード `agentic_rag_server` の `README.md` に記載しています。

## 環境セットアップ

以下の手順でクライアント側の環境をセットアップします。

### Node.jsバージョンの確認

Node.js はバージョン 18.17.0 および 20.18.0 での動作を確認済みです。

### 必要なOSSのインストール

ルートフォルダーで以下のコマンドを実行し、必要なOSSをインストールします。

```bash
npm install
```

## アプリケーションの起動

以下の手順に従ってアプリケーションを起動します。

### バックエンドの起動

- バックエンドコードのルートフォルダーで以下のコマンドを実行します。

```bash
uvicorn main:app
```

- サーバーが `http://127.0.0.1:8000` で起動します。

### フロントエンドの起動

- フロントエンドコードのルートフォルダーで以下のコマンドを実行します。

```bash
npm run dev
```

- フロントエンドが起動したら、ブラウザで [http://localhost:3000/](http://localhost:3000/) にアクセスします。チャットボットの画面が表示されます。

### 動作確認

- 質問入力欄に質問を入力して送信ボタンを押し、LLMから正常に回答が返ってくるか確認します。
  例： 「こんにちは」と入力し、回答が返ってくれば正常に動作しています。
- RAG機能の確認として、次の質問を行います。回答が正常に返ってくることを確認してください。
  「Fic-GreenLifeとFic-NextFoodの比較を技術的な観点で行って端的にまとめてください。」

※ Vector DBには、「Fic-GreenLife」「Fic-NextFood」「Fic-TechFrontier」という3つの架空企業の情報が格納されています。FicはFictionを意味します。
